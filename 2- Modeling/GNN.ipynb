{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx.algorithms.community as community\n",
    "import torch\n",
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn import GraphConv\n",
    "from IPython.display import Latex\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path as osp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch_geometric.transforms import NormalizeFeatures, RandomLinkSplit\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"../data/test_set_final.csv\")\n",
    "train_set = pd.read_csv(\"../data/train_set_final.csv\")\n",
    "true_test = pd.read_csv(\"../data/test.txt\", sep=\" \", header=None, names=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the 1 to 932 column named number_source into a single column as an array of values\n",
    "train_set['node_info_source'] = train_set[train_set.columns[20:952]].values.tolist()\n",
    "train_set.drop(train_set.columns[20:952], axis=1, inplace=True)\n",
    "test_set['node_info_source'] = test_set[test_set.columns[17:949]].values.tolist()\n",
    "test_set.drop(test_set.columns[19:951], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['node_info_target'] = train_set[train_set.columns[20:952]].values.tolist()\n",
    "train_set.drop(train_set.columns[20:952], axis=1, inplace=True)\n",
    "test_set['node_info_target'] = test_set[test_set.columns[17:949]].values.tolist()\n",
    "test_set.drop(test_set.columns[19:951], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m x_target_info \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_info_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Concaténez les nouvelles caractéristiques avec les caractéristiques existantes\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x_source \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_source_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_source_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_source_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m x_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_target_info, x_train_target_embedding, torch\u001b[38;5;241m.\u001b[39mtensor(x_target_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_source, x_target], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got Series"
     ]
    }
   ],
   "source": [
    "# Créez un graphique NetworkX\n",
    "G = nx.from_pandas_edgelist(train_set, 'source', 'target', 'label')\n",
    "\n",
    "# Convertissez le graphique en format PyG\n",
    "edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "# Créez des tenseurs pour vos étiquettes binaires\n",
    "y = torch.tensor(train_set['label'].values, dtype=torch.float)\n",
    "\n",
    "# Ajoutez des fonctionnalités supplémentaires pour chaque nœud\n",
    "# Par exemple, supposons que vous ayez deux nouvelles fonctionnalités pour chaque nœud : 'feature1' et 'feature2'\n",
    "x_source_features = train_set[['degree_source', 'centrality_source', 'community_source']].values\n",
    "x_target_features = train_set[['degree_target', 'centrality_target', 'community_target']].values\n",
    "\n",
    "# Concaténez les caractéristiques existantes avec les nouvelles caractéristiques\n",
    "x_source_info = torch.tensor(train_set['node_info_source'].values.tolist(), dtype=torch.float)\n",
    "x_target_info = torch.tensor(train_set['node_info_target'].values.tolist(), dtype=torch.float)\n",
    "\n",
    "# Concaténez les nouvelles caractéristiques avec les caractéristiques existantes\n",
    "x_source = torch.cat((x_source_info, torch.tensor(x_source_features, dtype=torch.float)), dim=1)\n",
    "x_target = torch.cat((x_target_info, torch.tensor(x_target_features, dtype=torch.float)), dim=1)\n",
    "\n",
    "x = torch.cat([x_source, x_target], dim=1)\n",
    "\n",
    "\n",
    "# Créez votre jeu de données PyG avec les nouvelles fonctionnalités\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Appliquer les transformations pour diviser les données en ensembles de train, validation et test\n",
    "transform = RandomLinkSplit(num_val=0.10, num_test=0.05, neg_sampling_ratio=1.0,\n",
    "                            is_undirected=True, add_negative_train_samples=False)\n",
    "transformed_data = transform(data)\n",
    "\n",
    "# Après avoir appliqué la transformation, les données sont transformées en une liste de tuples (train_data, val_data, test_data)\n",
    "train_data, val_data, test_data = transformed_data\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m x_target_features \u001b[38;5;241m=\u001b[39m test_set[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree_target\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentrality_target\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunity_target\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Concaténez les caractéristiques existantes avec les nouvelles caractéristiques\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x_source_info \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode_info_source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m x_target_info \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_info_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Concaténez les nouvelles caractéristiques avec les caractéristiques existantes\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# Créez un graphique NetworkX\n",
    "G = nx.from_pandas_edgelist(test_set, 'source', 'target')\n",
    "\n",
    "# Convertissez le graphique en format PyG\n",
    "edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "\n",
    "# Ajoutez des fonctionnalités supplémentaires pour chaque nœud\n",
    "# Par exemple, supposons que vous ayez deux nouvelles fonctionnalités pour chaque nœud : 'feature1' et 'feature2'\n",
    "x_source_features = test_set[['degree_source', 'centrality_source', 'community_source']].values\n",
    "x_target_features = test_set[['degree_target', 'centrality_target', 'community_target']].values\n",
    "\n",
    "# Concaténez les caractéristiques existantes avec les nouvelles caractéristiques\n",
    "x_source_info = torch.tensor(test_set['node_info_source'].values.tolist(), dtype=torch.float)\n",
    "x_target_info = torch.tensor(test_set['node_info_target'].values.tolist(), dtype=torch.float)\n",
    "\n",
    "# Concaténez les nouvelles caractéristiques avec les caractéristiques existantes\n",
    "x_source = torch.cat((x_source_info, torch.tensor(x_source_features, dtype=torch.float)), dim=1)\n",
    "x_target = torch.cat((x_target_info, torch.tensor(x_target_features, dtype=torch.float)), dim=1)\n",
    "\n",
    "x = torch.cat([x_source, x_target], dim=1)\n",
    "\n",
    "# Supposons que num_nodes soit le nombre total de nœuds dans votre graphe\n",
    "num_nodes = max(max(edge_index[0]), max(edge_index[1])) + 1\n",
    "\n",
    "# Calculez le nombre de nœuds isolés\n",
    "num_isolated_nodes = num_nodes - x.size(0)\n",
    "\n",
    "# Créez un tensor de zéros de la taille appropriée\n",
    "isolated_nodes = torch.zeros((num_isolated_nodes, x.size(1)))\n",
    "\n",
    "# Concaténez le tensor de zéros à x\n",
    "x = torch.cat([x, isolated_nodes], dim=0)\n",
    "\n",
    "# Créez votre jeu de données PyG avec les nouvelles fonctionnalités\n",
    "data_test = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index contains node indices that are out of bounds!\n"
     ]
    }
   ],
   "source": [
    "if data_test.edge_index.max() >= data_test.x.size(0):\n",
    "    print(\"edge_index contains node indices that are out of bounds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3498, 1870], edge_index=[2, 3498])\n"
     ]
    }
   ],
   "source": [
    "print(data_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7599)\n"
     ]
    }
   ],
   "source": [
    "print(data_test.edge_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498\n"
     ]
    }
   ],
   "source": [
    "print(data_test.x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4423)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.edge_index[0] <= train_data.edge_index[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'edge_index' contains larger indices than the number of nodes (3498) in 'Data' (found 7599)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/data.py:691\u001b[0m, in \u001b[0;36mData.validate\u001b[0;34m(self, raise_on_error)\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_nodes:\n\u001b[1;32m    690\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m         \u001b[43mwarn_or_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m contains larger indices than the number \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mof nodes (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) in \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcls_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(found \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/data.py:1186\u001b[0m, in \u001b[0;36mwarn_or_raise\u001b[0;34m(msg, raise_on_error)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarn_or_raise\u001b[39m(msg: \u001b[38;5;28mstr\u001b[39m, raise_on_error: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error:\n\u001b[0;32m-> 1186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1188\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: 'edge_index' contains larger indices than the number of nodes (3498) in 'Data' (found 7599)"
     ]
    }
   ],
   "source": [
    "data_test.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  # Ajout d'une couche supplémentaire\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(0.5)  # Ajout d'une couche de dropout\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)  # Utilisation de dropout après la première couche\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)  # Utilisation de dropout après la deuxième couche\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "    def forward(self, data):\n",
    "        if data.edge_label_index is not None:\n",
    "            z = self.encode(data.x, data.edge_index)\n",
    "            return self.decode(z, data.edge_label_index)\n",
    "        else:\n",
    "            z = self.encode(data.x, data.edge_index)\n",
    "            return self.decode_all(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer votre modèle en fonction du nombre de fonctionnalités des nœuds\n",
    "num_features = train_data.x.size(1)  # Nombre de fonctionnalités des nœuds source (ou target)\n",
    "model = Net(num_features, 128, 64)\n",
    "\n",
    "# Créer l'optimiseur Adam\n",
    "optimizer = Adam(params=model.parameters(), lr=0.01)\n",
    "\n",
    "# Créer la fonction de perte BCEWithLogitsLoss\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1))\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 10.4765, Val: 0.6170, Test: 0.6137\n",
      "Epoch: 002, Loss: 3.7997, Val: 0.6169, Test: 0.6234\n",
      "Epoch: 003, Loss: 1.2886, Val: 0.5168, Test: 0.5332\n",
      "Epoch: 004, Loss: 1.0284, Val: 0.4738, Test: 0.4717\n",
      "Epoch: 005, Loss: 0.8455, Val: 0.5335, Test: 0.5041\n",
      "Epoch: 006, Loss: 0.7628, Val: 0.5644, Test: 0.5298\n",
      "Epoch: 007, Loss: 0.7631, Val: 0.5824, Test: 0.5468\n",
      "Epoch: 008, Loss: 0.7221, Val: 0.6016, Test: 0.5684\n",
      "Epoch: 009, Loss: 0.7144, Val: 0.6275, Test: 0.5923\n",
      "Epoch: 010, Loss: 0.7217, Val: 0.6503, Test: 0.6170\n",
      "Epoch: 011, Loss: 0.6914, Val: 0.6544, Test: 0.6256\n",
      "Epoch: 012, Loss: 0.6850, Val: 0.6556, Test: 0.6293\n",
      "Epoch: 013, Loss: 0.6866, Val: 0.6551, Test: 0.6307\n",
      "Epoch: 014, Loss: 0.6795, Val: 0.6548, Test: 0.6295\n",
      "Epoch: 015, Loss: 0.6693, Val: 0.6560, Test: 0.6307\n",
      "Epoch: 016, Loss: 0.6735, Val: 0.6610, Test: 0.6356\n",
      "Epoch: 017, Loss: 0.6828, Val: 0.6716, Test: 0.6435\n",
      "Epoch: 018, Loss: 0.6700, Val: 0.6868, Test: 0.6511\n",
      "Epoch: 019, Loss: 0.6725, Val: 0.6985, Test: 0.6651\n",
      "Epoch: 020, Loss: 0.6598, Val: 0.7038, Test: 0.6720\n",
      "Epoch: 021, Loss: 0.6678, Val: 0.7088, Test: 0.6803\n",
      "Epoch: 022, Loss: 0.6678, Val: 0.7149, Test: 0.6891\n",
      "Epoch: 023, Loss: 0.6679, Val: 0.7248, Test: 0.7031\n",
      "Epoch: 024, Loss: 0.6618, Val: 0.7359, Test: 0.7201\n",
      "Epoch: 025, Loss: 0.6568, Val: 0.7374, Test: 0.7239\n",
      "Epoch: 026, Loss: 0.6512, Val: 0.7425, Test: 0.7261\n",
      "Epoch: 027, Loss: 0.6405, Val: 0.7381, Test: 0.7213\n",
      "Epoch: 028, Loss: 0.6782, Val: 0.7486, Test: 0.7344\n",
      "Epoch: 029, Loss: 0.6336, Val: 0.7496, Test: 0.7370\n",
      "Epoch: 030, Loss: 0.6265, Val: 0.7413, Test: 0.7303\n",
      "Epoch: 031, Loss: 0.6269, Val: 0.7488, Test: 0.7388\n",
      "Epoch: 032, Loss: 0.6223, Val: 0.7606, Test: 0.7562\n",
      "Epoch: 033, Loss: 0.6139, Val: 0.7709, Test: 0.7674\n",
      "Epoch: 034, Loss: 0.6131, Val: 0.7773, Test: 0.7753\n",
      "Epoch: 035, Loss: 0.5958, Val: 0.7817, Test: 0.7819\n",
      "Epoch: 036, Loss: 0.6102, Val: 0.7837, Test: 0.7816\n",
      "Epoch: 037, Loss: 0.5954, Val: 0.7832, Test: 0.7776\n",
      "Epoch: 038, Loss: 0.5883, Val: 0.7792, Test: 0.7724\n",
      "Epoch: 039, Loss: 0.5835, Val: 0.7785, Test: 0.7710\n",
      "Epoch: 040, Loss: 0.5884, Val: 0.7844, Test: 0.7771\n",
      "Epoch: 041, Loss: 0.5844, Val: 0.7910, Test: 0.7833\n",
      "Epoch: 042, Loss: 0.5700, Val: 0.7949, Test: 0.7871\n",
      "Epoch: 043, Loss: 0.5736, Val: 0.7960, Test: 0.7879\n",
      "Epoch: 044, Loss: 0.5864, Val: 0.7951, Test: 0.7856\n",
      "Epoch: 045, Loss: 0.5781, Val: 0.7963, Test: 0.7855\n",
      "Epoch: 046, Loss: 0.5780, Val: 0.7999, Test: 0.7880\n",
      "Epoch: 047, Loss: 0.5755, Val: 0.8015, Test: 0.7910\n",
      "Epoch: 048, Loss: 0.5732, Val: 0.8051, Test: 0.7958\n",
      "Epoch: 049, Loss: 0.5810, Val: 0.8066, Test: 0.7980\n",
      "Epoch: 050, Loss: 0.5636, Val: 0.8079, Test: 0.7990\n",
      "Epoch: 051, Loss: 0.5520, Val: 0.8123, Test: 0.8016\n",
      "Epoch: 052, Loss: 0.5532, Val: 0.8163, Test: 0.8037\n",
      "Epoch: 053, Loss: 0.5549, Val: 0.8186, Test: 0.8056\n",
      "Epoch: 054, Loss: 0.5625, Val: 0.8172, Test: 0.8035\n",
      "Epoch: 055, Loss: 0.5613, Val: 0.8173, Test: 0.8022\n",
      "Epoch: 056, Loss: 0.5493, Val: 0.8153, Test: 0.8005\n",
      "Epoch: 057, Loss: 0.5585, Val: 0.8169, Test: 0.8043\n",
      "Epoch: 058, Loss: 0.5617, Val: 0.8196, Test: 0.8122\n",
      "Epoch: 059, Loss: 0.5452, Val: 0.8204, Test: 0.8179\n",
      "Epoch: 060, Loss: 0.5502, Val: 0.8220, Test: 0.8204\n",
      "Epoch: 061, Loss: 0.5426, Val: 0.8256, Test: 0.8199\n",
      "Epoch: 062, Loss: 0.5437, Val: 0.8278, Test: 0.8218\n",
      "Epoch: 063, Loss: 0.5516, Val: 0.8271, Test: 0.8211\n",
      "Epoch: 064, Loss: 0.5387, Val: 0.8246, Test: 0.8176\n",
      "Epoch: 065, Loss: 0.5378, Val: 0.8235, Test: 0.8155\n",
      "Epoch: 066, Loss: 0.5430, Val: 0.8246, Test: 0.8175\n",
      "Epoch: 067, Loss: 0.5398, Val: 0.8254, Test: 0.8229\n",
      "Epoch: 068, Loss: 0.5405, Val: 0.8263, Test: 0.8284\n",
      "Epoch: 069, Loss: 0.5300, Val: 0.8293, Test: 0.8341\n",
      "Epoch: 070, Loss: 0.5355, Val: 0.8322, Test: 0.8376\n",
      "Epoch: 071, Loss: 0.5307, Val: 0.8321, Test: 0.8386\n",
      "Epoch: 072, Loss: 0.5282, Val: 0.8325, Test: 0.8417\n",
      "Epoch: 073, Loss: 0.5266, Val: 0.8320, Test: 0.8447\n",
      "Epoch: 074, Loss: 0.5235, Val: 0.8322, Test: 0.8458\n",
      "Epoch: 075, Loss: 0.5280, Val: 0.8345, Test: 0.8474\n",
      "Epoch: 076, Loss: 0.5248, Val: 0.8377, Test: 0.8483\n",
      "Epoch: 077, Loss: 0.5228, Val: 0.8390, Test: 0.8514\n",
      "Epoch: 078, Loss: 0.5198, Val: 0.8378, Test: 0.8532\n",
      "Epoch: 079, Loss: 0.5212, Val: 0.8368, Test: 0.8530\n",
      "Epoch: 080, Loss: 0.5152, Val: 0.8355, Test: 0.8526\n",
      "Epoch: 081, Loss: 0.5202, Val: 0.8352, Test: 0.8535\n",
      "Epoch: 082, Loss: 0.5219, Val: 0.8357, Test: 0.8547\n",
      "Epoch: 083, Loss: 0.5203, Val: 0.8373, Test: 0.8573\n",
      "Epoch: 084, Loss: 0.5217, Val: 0.8402, Test: 0.8603\n",
      "Epoch: 085, Loss: 0.5119, Val: 0.8446, Test: 0.8628\n",
      "Epoch: 086, Loss: 0.5128, Val: 0.8477, Test: 0.8636\n",
      "Epoch: 087, Loss: 0.5119, Val: 0.8491, Test: 0.8645\n",
      "Epoch: 088, Loss: 0.5126, Val: 0.8481, Test: 0.8654\n",
      "Epoch: 089, Loss: 0.5066, Val: 0.8481, Test: 0.8659\n",
      "Epoch: 090, Loss: 0.5084, Val: 0.8482, Test: 0.8663\n",
      "Epoch: 091, Loss: 0.5087, Val: 0.8484, Test: 0.8660\n",
      "Epoch: 092, Loss: 0.5125, Val: 0.8487, Test: 0.8664\n",
      "Epoch: 093, Loss: 0.5064, Val: 0.8486, Test: 0.8676\n",
      "Epoch: 094, Loss: 0.5051, Val: 0.8494, Test: 0.8675\n",
      "Epoch: 095, Loss: 0.5135, Val: 0.8505, Test: 0.8674\n",
      "Epoch: 096, Loss: 0.5044, Val: 0.8508, Test: 0.8686\n",
      "Epoch: 097, Loss: 0.5001, Val: 0.8514, Test: 0.8709\n",
      "Epoch: 098, Loss: 0.4965, Val: 0.8534, Test: 0.8729\n",
      "Epoch: 099, Loss: 0.4999, Val: 0.8551, Test: 0.8751\n",
      "Epoch: 100, Loss: 0.5053, Val: 0.8553, Test: 0.8773\n",
      "Final Test: 0.8773\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test.edge_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(data_test.x, data_test.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800507</th>\n",
       "      <td>7599</td>\n",
       "      <td>7576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800508</th>\n",
       "      <td>7599</td>\n",
       "      <td>7579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800509</th>\n",
       "      <td>7599</td>\n",
       "      <td>7593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800510</th>\n",
       "      <td>7599</td>\n",
       "      <td>7594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800511</th>\n",
       "      <td>7599</td>\n",
       "      <td>7599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  target  Predicted\n",
       "0              0       0          1\n",
       "1              0       1          1\n",
       "2              0       3          1\n",
       "3              0       6          1\n",
       "4              0       9          1\n",
       "...          ...     ...        ...\n",
       "43800507    7599    7576          1\n",
       "43800508    7599    7579          1\n",
       "43800509    7599    7593          1\n",
       "43800510    7599    7594          1\n",
       "43800511    7599    7599          1\n",
       "\n",
       "[43800512 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertissez final_edge_index en un DataFrame\n",
    "predictions_df = pd.DataFrame(final_edge_index.t().numpy(), columns=['source', 'target'])\n",
    "\n",
    "# Ajoutez une colonne 'Predicted' avec toutes les valeurs à 1\n",
    "# puisque final_edge_index contient seulement les arêtes prédites\n",
    "predictions_df['Predicted'] = 1\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3425</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4832</td>\n",
       "      <td>6317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4984</td>\n",
       "      <td>7298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385</td>\n",
       "      <td>5481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1548</td>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>717</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>1731</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>426</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>992</td>\n",
       "      <td>1755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target\n",
       "0       3425    4524\n",
       "1       1620    2617\n",
       "2       4832    6317\n",
       "3       4984    7298\n",
       "4        385    5481\n",
       "...      ...     ...\n",
       "3493    1548    2957\n",
       "3494     717    1756\n",
       "3495    1731    3976\n",
       "3496     426    1120\n",
       "3497     992    1755\n",
       "\n",
       "[3498 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = true_test.merge(predictions_df, on=['source', 'target'], how='left')\n",
    "merged_df['Predicted'] = merged_df['Predicted'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3425</td>\n",
       "      <td>4524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620</td>\n",
       "      <td>2617</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4832</td>\n",
       "      <td>6317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4984</td>\n",
       "      <td>7298</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385</td>\n",
       "      <td>5481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1548</td>\n",
       "      <td>2957</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>717</td>\n",
       "      <td>1756</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>1731</td>\n",
       "      <td>3976</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>426</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>992</td>\n",
       "      <td>1755</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target  Predicted\n",
       "0       3425    4524        1.0\n",
       "1       1620    2617        1.0\n",
       "2       4832    6317        1.0\n",
       "3       4984    7298        1.0\n",
       "4        385    5481        1.0\n",
       "...      ...     ...        ...\n",
       "3493    1548    2957        1.0\n",
       "3494     717    1756        1.0\n",
       "3495    1731    3976        1.0\n",
       "3496     426    1120        1.0\n",
       "3497     992    1755        1.0\n",
       "\n",
       "[3498 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with index and predicted labels\n",
    "submission = pd.DataFrame({'ID': merged_df.index, 'Predicted': merged_df.Predicted})\n",
    "\n",
    "submission.to_csv('../submission/predictions_gnn_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

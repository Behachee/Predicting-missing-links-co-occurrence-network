{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx.algorithms.community as community\n",
    "import torch\n",
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn import GraphConv\n",
    "from IPython.display import Latex\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path as osp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch_geometric.transforms import NormalizeFeatures, RandomLinkSplit\n",
    "import networkx as nx\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"../data/test_set_final.csv\")\n",
    "train_set = pd.read_csv(\"../data/train_set_final.csv\")\n",
    "true_test = pd.read_csv(\"../data/test.txt\", sep=\" \", header=None, names=['source', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the 1 to 932 column named number_source into a single column as an array of values\n",
    "train_set['node_info_source'] = train_set[train_set.columns[20:952]].values.tolist()\n",
    "train_set.drop(train_set.columns[20:952], axis=1, inplace=True)\n",
    "test_set['node_info_source'] = test_set[test_set.columns[17:949]].values.tolist()\n",
    "test_set.drop(test_set.columns[19:951], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['node_info_target'] = train_set[train_set.columns[20:952]].values.tolist()\n",
    "train_set.drop(train_set.columns[20:952], axis=1, inplace=True)\n",
    "test_set['node_info_target'] = test_set[test_set.columns[17:949]].values.tolist()\n",
    "test_set.drop(test_set.columns[19:951], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[10496, 1870], edge_index=[2, 8788], y=[10496], edge_label=[4394], edge_label_index=[2, 4394])\n",
      "Data(x=[10496, 1870], edge_index=[2, 8788], y=[10496], edge_label=[1032], edge_label_index=[2, 1032])\n",
      "Data(x=[10496, 1870], edge_index=[2, 9820], y=[10496], edge_label=[516], edge_label_index=[2, 516])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code snippet creates a graph using NetworkX and converts it to PyG format. It then prepares the data for training a Graph Neural Network (GNN) model.\n",
    "\n",
    "The steps involved are as follows:\n",
    "1. Create a NetworkX graph from a pandas DataFrame called 'train_set', using the columns 'source', 'target', and 'label'.\n",
    "2. Convert the graph to PyG format by creating a tensor 'edge_index' from the graph's edges.\n",
    "3. Create tensors for binary labels using the 'label' column of 'train_set'.\n",
    "4. Extract additional node features from 'train_set' and concatenate them with existing features.\n",
    "5. Create tensors for node information from 'train_set' and concatenate them with the additional features.\n",
    "6. Concatenate the source and target tensors to create the final feature tensor 'x'.\n",
    "7. Create a PyG Data object with the feature tensor, edge index, and label tensor.\n",
    "8. Apply transformations to split the data into train, validation, and test sets.\n",
    "9. Print the train, validation, and test data.\n",
    "\n",
    "Note: The code assumes the existence of certain columns in the 'train_set' DataFrame, such as 'degree_source', 'centrality_source', 'community_source', 'degree_target', 'centrality_target', 'community_target', 'node_info_source', and 'node_info_target'.\n",
    "\"\"\"\n",
    "\n",
    "G = nx.from_pandas_edgelist(train_set, 'source', 'target', 'label')\n",
    "edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "y = torch.tensor(train_set['label'].values, dtype=torch.float)\n",
    "x_source_features = train_set[['degree_source', 'centrality_source', 'community_source']].values\n",
    "x_target_features = train_set[['degree_target', 'centrality_target', 'community_target']].values\n",
    "x_source_info = torch.tensor(train_set['node_info_source'].values.tolist(), dtype=torch.float)\n",
    "x_target_info = torch.tensor(train_set['node_info_target'].values.tolist(), dtype=torch.float)\n",
    "x_source = torch.cat((x_source_info, torch.tensor(x_source_features, dtype=torch.float)), dim=1)\n",
    "x_target = torch.cat((x_target_info, torch.tensor(x_target_features, dtype=torch.float)), dim=1)\n",
    "x = torch.cat([x_source, x_target], dim=1)\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "transform = RandomLinkSplit(num_val=0.10, num_test=0.05, neg_sampling_ratio=1.0, is_undirected=True, add_negative_train_samples=False)\n",
    "transformed_data = transform(data)\n",
    "train_data, val_data, test_data = transformed_data\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyg_dataset(test_set):\n",
    "    \"\"\"\n",
    "    Create a PyG dataset from a given test set.\n",
    "\n",
    "    Args:\n",
    "        test_set (pandas.DataFrame): The test set containing the edge information.\n",
    "\n",
    "    Returns:\n",
    "        data_test (torch_geometric.data.Data): The PyG dataset with the new features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a NetworkX graph\n",
    "    G = nx.from_pandas_edgelist(test_set, 'source', 'target')\n",
    "\n",
    "    # Convert the graph to PyG format\n",
    "    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "    # Add additional features for each node\n",
    "    x_source_features = test_set[['degree_source', 'centrality_source', 'community_source']].values\n",
    "    x_target_features = test_set[['degree_target', 'centrality_target', 'community_target']].values\n",
    "\n",
    "    # Concatenate the existing features with the new features\n",
    "    x_source_info = torch.tensor(test_set['node_info_source'].values.tolist(), dtype=torch.float)\n",
    "    x_target_info = torch.tensor(test_set['node_info_target'].values.tolist(), dtype=torch.float)\n",
    "\n",
    "    # Concatenate the new features with the existing features\n",
    "    x_source = torch.cat((x_source_info, torch.tensor(x_source_features, dtype=torch.float)), dim=1)\n",
    "    x_target = torch.cat((x_target_info, torch.tensor(x_target_features, dtype=torch.float)), dim=1)\n",
    "\n",
    "    x = torch.cat([x_source, x_target], dim=1)\n",
    "\n",
    "    # Calculate the number of isolated nodes\n",
    "    num_nodes = max(max(edge_index[0]), max(edge_index[1])) + 1\n",
    "    num_isolated_nodes = num_nodes - x.size(0)\n",
    "\n",
    "    # Create a tensor of zeros of the appropriate size\n",
    "    isolated_nodes = torch.zeros((num_isolated_nodes, x.size(1)))\n",
    "\n",
    "    # Concatenate the tensor of zeros to x\n",
    "    x = torch.cat([x, isolated_nodes], dim=0)\n",
    "\n",
    "    # Create your PyG dataset with the new features\n",
    "    data_test = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    return data_test\n",
    "\n",
    "data_test = create_pyg_dataset(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test.edge_index.max() >= data_test.x.size(0):\n",
    "    print(\"edge_index contains node indices that are out of bounds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A graph neural network model for link prediction.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        hidden_channels (int): Number of hidden channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (GCNConv): First graph convolutional layer.\n",
    "        conv2 (GCNConv): Second graph convolutional layer.\n",
    "        conv3 (GCNConv): Third graph convolutional layer.\n",
    "        dropout (torch.nn.Dropout): Dropout layer.\n",
    "\n",
    "    Methods:\n",
    "        encode: Encodes the input features and computes node embeddings.\n",
    "        decode: Decodes the node embeddings to predict the existence of a specific edge.\n",
    "        decode_all: Decodes all node embeddings to predict the existence of all possible edges.\n",
    "        forward: Performs the forward pass of the model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  \n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(0.5)  \n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Encodes the input features and computes node embeddings.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features.\n",
    "            edge_index (torch.Tensor): Graph edge indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Node embeddings.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)  \n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)  \n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        \"\"\"\n",
    "        Decodes the node embeddings to predict the existence of a specific edge.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Node embeddings.\n",
    "            edge_label_index (torch.Tensor): Indices of the specific edge.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted existence of the specific edge.\n",
    "\n",
    "        \"\"\"\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        \"\"\"\n",
    "        Decodes all node embeddings to predict the existence of all possible edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Node embeddings.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted existence of all possible edges.\n",
    "\n",
    "        \"\"\"\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            data: Input data containing node features and graph information.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted existence of edges.\n",
    "\n",
    "        \"\"\"\n",
    "        if data.edge_label_index is not None:\n",
    "            z = self.encode(data.x, data.edge_index)\n",
    "            return self.decode(z, data.edge_label_index)\n",
    "        else:\n",
    "            z = self.encode(data.x, data.edge_index)\n",
    "            return self.decode_all(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model instance\n",
    "num_features = train_data.x.size(1) \n",
    "model = Net(num_features, 128, 64)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(params=model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Trains the model using the provided training data.\n",
    "\n",
    "    Returns:\n",
    "        loss (torch.Tensor): The loss value after training.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1))\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    \n",
    "\n",
    "    # Calculate accuracy\n",
    "    predicted_labels = out.sigmoid().round()\n",
    "    accuracy = (predicted_labels == edge_label).sum().item() / edge_label.size(0)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model on the test data.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): The test data.\n",
    "\n",
    "    Returns:\n",
    "        float: The ROC AUC score of the model's predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6916, Val_auc: 0.5627, Test_auc: 0.5639 Accuracy: 0.5472\n",
      "Epoch: 002, Loss: 0.6878, Val_auc: 0.5629, Test_auc: 0.5696 Accuracy: 0.5566\n",
      "Epoch: 003, Loss: 0.6814, Val_auc: 0.5659, Test_auc: 0.5717 Accuracy: 0.5553\n",
      "Epoch: 004, Loss: 0.6849, Val_auc: 0.5663, Test_auc: 0.5670 Accuracy: 0.5543\n",
      "Epoch: 005, Loss: 0.7209, Val_auc: 0.5646, Test_auc: 0.5598 Accuracy: 0.5493\n",
      "Epoch: 006, Loss: 0.6827, Val_auc: 0.5618, Test_auc: 0.5572 Accuracy: 0.5485\n",
      "Epoch: 007, Loss: 0.6848, Val_auc: 0.5594, Test_auc: 0.5505 Accuracy: 0.5493\n",
      "Epoch: 008, Loss: 0.6811, Val_auc: 0.5556, Test_auc: 0.5486 Accuracy: 0.5481\n",
      "Epoch: 009, Loss: 0.6871, Val_auc: 0.5509, Test_auc: 0.5466 Accuracy: 0.5470\n",
      "Epoch: 010, Loss: 0.6880, Val_auc: 0.5482, Test_auc: 0.5447 Accuracy: 0.5420\n",
      "Epoch: 011, Loss: 0.7032, Val_auc: 0.5490, Test_auc: 0.5428 Accuracy: 0.5473\n",
      "Epoch: 012, Loss: 0.6797, Val_auc: 0.5480, Test_auc: 0.5428 Accuracy: 0.5497\n",
      "Epoch: 013, Loss: 0.6827, Val_auc: 0.5474, Test_auc: 0.5448 Accuracy: 0.5437\n",
      "Epoch: 014, Loss: 0.6852, Val_auc: 0.5493, Test_auc: 0.5448 Accuracy: 0.5511\n",
      "Epoch: 015, Loss: 0.6876, Val_auc: 0.5511, Test_auc: 0.5447 Accuracy: 0.5489\n",
      "Epoch: 016, Loss: 0.6861, Val_auc: 0.5529, Test_auc: 0.5428 Accuracy: 0.5448\n",
      "Epoch: 017, Loss: 0.6828, Val_auc: 0.5529, Test_auc: 0.5428 Accuracy: 0.5394\n",
      "Epoch: 018, Loss: 0.6846, Val_auc: 0.5531, Test_auc: 0.5447 Accuracy: 0.5482\n",
      "Epoch: 019, Loss: 0.6814, Val_auc: 0.5552, Test_auc: 0.5447 Accuracy: 0.5431\n",
      "Epoch: 020, Loss: 0.6812, Val_auc: 0.5580, Test_auc: 0.5485 Accuracy: 0.5459\n",
      "Epoch: 021, Loss: 0.6808, Val_auc: 0.5600, Test_auc: 0.5485 Accuracy: 0.5383\n",
      "Epoch: 022, Loss: 0.6827, Val_auc: 0.5611, Test_auc: 0.5488 Accuracy: 0.5462\n",
      "Epoch: 023, Loss: 0.6827, Val_auc: 0.5630, Test_auc: 0.5526 Accuracy: 0.5431\n",
      "Epoch: 024, Loss: 0.6814, Val_auc: 0.5616, Test_auc: 0.5525 Accuracy: 0.5449\n",
      "Epoch: 025, Loss: 0.6821, Val_auc: 0.5635, Test_auc: 0.5545 Accuracy: 0.5506\n",
      "Epoch: 026, Loss: 0.6846, Val_auc: 0.5636, Test_auc: 0.5545 Accuracy: 0.5471\n",
      "Epoch: 027, Loss: 0.8320, Val_auc: 0.5643, Test_auc: 0.5526 Accuracy: 0.5451\n",
      "Epoch: 028, Loss: 0.6811, Val_auc: 0.5615, Test_auc: 0.5526 Accuracy: 0.5437\n",
      "Epoch: 029, Loss: 0.6837, Val_auc: 0.5594, Test_auc: 0.5488 Accuracy: 0.5436\n",
      "Epoch: 030, Loss: 0.6796, Val_auc: 0.5573, Test_auc: 0.5488 Accuracy: 0.5449\n",
      "Epoch: 031, Loss: 0.6859, Val_auc: 0.5608, Test_auc: 0.5526 Accuracy: 0.5454\n",
      "Epoch: 032, Loss: 0.6821, Val_auc: 0.5573, Test_auc: 0.5564 Accuracy: 0.5445\n",
      "Epoch: 033, Loss: 0.6821, Val_auc: 0.5608, Test_auc: 0.5565 Accuracy: 0.5449\n",
      "Epoch: 034, Loss: 0.6812, Val_auc: 0.5646, Test_auc: 0.5545 Accuracy: 0.5440\n",
      "Epoch: 035, Loss: 0.6856, Val_auc: 0.5674, Test_auc: 0.5530 Accuracy: 0.5415\n",
      "Epoch: 036, Loss: 0.6798, Val_auc: 0.5665, Test_auc: 0.5510 Accuracy: 0.5420\n",
      "Epoch: 037, Loss: 0.6816, Val_auc: 0.5667, Test_auc: 0.5530 Accuracy: 0.5481\n",
      "Epoch: 038, Loss: 0.6868, Val_auc: 0.5678, Test_auc: 0.5583 Accuracy: 0.5456\n",
      "Epoch: 039, Loss: 0.6829, Val_auc: 0.5724, Test_auc: 0.5640 Accuracy: 0.5456\n",
      "Epoch: 040, Loss: 0.7353, Val_auc: 0.5705, Test_auc: 0.5679 Accuracy: 0.5492\n",
      "Epoch: 041, Loss: 0.6827, Val_auc: 0.5736, Test_auc: 0.5665 Accuracy: 0.5485\n",
      "Epoch: 042, Loss: 0.6777, Val_auc: 0.5784, Test_auc: 0.5703 Accuracy: 0.5505\n",
      "Epoch: 043, Loss: 0.6809, Val_auc: 0.5832, Test_auc: 0.5772 Accuracy: 0.5498\n",
      "Epoch: 044, Loss: 0.7227, Val_auc: 0.5854, Test_auc: 0.5753 Accuracy: 0.5493\n",
      "Epoch: 045, Loss: 0.6869, Val_auc: 0.5873, Test_auc: 0.5810 Accuracy: 0.5504\n",
      "Epoch: 046, Loss: 0.6782, Val_auc: 0.5880, Test_auc: 0.5831 Accuracy: 0.5479\n",
      "Epoch: 047, Loss: 0.6884, Val_auc: 0.5898, Test_auc: 0.5869 Accuracy: 0.5534\n",
      "Epoch: 048, Loss: 0.6770, Val_auc: 0.5985, Test_auc: 0.5948 Accuracy: 0.5527\n",
      "Epoch: 049, Loss: 0.6871, Val_auc: 0.6070, Test_auc: 0.6022 Accuracy: 0.5510\n",
      "Epoch: 050, Loss: 0.6769, Val_auc: 0.6087, Test_auc: 0.6101 Accuracy: 0.5534\n",
      "Epoch: 051, Loss: 0.6803, Val_auc: 0.6082, Test_auc: 0.6152 Accuracy: 0.5489\n",
      "Epoch: 052, Loss: 0.6786, Val_auc: 0.6182, Test_auc: 0.6148 Accuracy: 0.5526\n",
      "Epoch: 053, Loss: 0.6770, Val_auc: 0.6232, Test_auc: 0.6180 Accuracy: 0.5550\n",
      "Epoch: 054, Loss: 0.6766, Val_auc: 0.6288, Test_auc: 0.6239 Accuracy: 0.5588\n",
      "Epoch: 055, Loss: 0.6778, Val_auc: 0.6305, Test_auc: 0.6196 Accuracy: 0.5525\n",
      "Epoch: 056, Loss: 0.6771, Val_auc: 0.6305, Test_auc: 0.6239 Accuracy: 0.5528\n",
      "Epoch: 057, Loss: 0.6741, Val_auc: 0.6373, Test_auc: 0.6121 Accuracy: 0.5538\n",
      "Epoch: 058, Loss: 0.6762, Val_auc: 0.6438, Test_auc: 0.6107 Accuracy: 0.5581\n",
      "Epoch: 059, Loss: 0.6835, Val_auc: 0.6431, Test_auc: 0.6087 Accuracy: 0.5609\n",
      "Epoch: 060, Loss: 0.6912, Val_auc: 0.6424, Test_auc: 0.6037 Accuracy: 0.5645\n",
      "Epoch: 061, Loss: 0.6746, Val_auc: 0.6481, Test_auc: 0.5893 Accuracy: 0.5650\n",
      "Epoch: 062, Loss: 0.6829, Val_auc: 0.6502, Test_auc: 0.5878 Accuracy: 0.5649\n",
      "Epoch: 063, Loss: 0.6823, Val_auc: 0.6491, Test_auc: 0.5894 Accuracy: 0.5652\n",
      "Epoch: 064, Loss: 0.7066, Val_auc: 0.6496, Test_auc: 0.5935 Accuracy: 0.5666\n",
      "Epoch: 065, Loss: 0.6743, Val_auc: 0.6466, Test_auc: 0.5931 Accuracy: 0.5721\n",
      "Epoch: 066, Loss: 0.6735, Val_auc: 0.6524, Test_auc: 0.6048 Accuracy: 0.5809\n",
      "Epoch: 067, Loss: 0.6780, Val_auc: 0.6556, Test_auc: 0.6181 Accuracy: 0.5857\n",
      "Epoch: 068, Loss: 0.6704, Val_auc: 0.6537, Test_auc: 0.6274 Accuracy: 0.5863\n",
      "Epoch: 069, Loss: 0.6795, Val_auc: 0.6591, Test_auc: 0.6394 Accuracy: 0.5767\n",
      "Epoch: 070, Loss: 0.6781, Val_auc: 0.6598, Test_auc: 0.6518 Accuracy: 0.5700\n",
      "Epoch: 071, Loss: 0.6791, Val_auc: 0.6588, Test_auc: 0.6583 Accuracy: 0.5702\n",
      "Epoch: 072, Loss: 0.6730, Val_auc: 0.6619, Test_auc: 0.6564 Accuracy: 0.5624\n",
      "Epoch: 073, Loss: 0.6747, Val_auc: 0.6633, Test_auc: 0.6537 Accuracy: 0.5712\n",
      "Epoch: 074, Loss: 0.6712, Val_auc: 0.6651, Test_auc: 0.6669 Accuracy: 0.5677\n",
      "Epoch: 075, Loss: 0.6708, Val_auc: 0.6653, Test_auc: 0.6637 Accuracy: 0.5695\n",
      "Epoch: 076, Loss: 0.6751, Val_auc: 0.6610, Test_auc: 0.6666 Accuracy: 0.5772\n",
      "Epoch: 077, Loss: 0.6730, Val_auc: 0.6642, Test_auc: 0.6626 Accuracy: 0.5802\n",
      "Epoch: 078, Loss: 0.6902, Val_auc: 0.6562, Test_auc: 0.6546 Accuracy: 0.5880\n",
      "Epoch: 079, Loss: 0.6841, Val_auc: 0.6478, Test_auc: 0.6641 Accuracy: 0.6004\n",
      "Epoch: 080, Loss: 0.6753, Val_auc: 0.6640, Test_auc: 0.6637 Accuracy: 0.6099\n",
      "Epoch: 081, Loss: 0.6861, Val_auc: 0.6734, Test_auc: 0.6499 Accuracy: 0.6046\n",
      "Epoch: 082, Loss: 0.6740, Val_auc: 0.6708, Test_auc: 0.6669 Accuracy: 0.5921\n",
      "Epoch: 083, Loss: 0.6754, Val_auc: 0.6709, Test_auc: 0.6632 Accuracy: 0.5927\n",
      "Epoch: 084, Loss: 0.6685, Val_auc: 0.6739, Test_auc: 0.6679 Accuracy: 0.5872\n",
      "Epoch: 085, Loss: 0.6722, Val_auc: 0.6727, Test_auc: 0.6662 Accuracy: 0.5769\n",
      "Epoch: 086, Loss: 0.6675, Val_auc: 0.6737, Test_auc: 0.6555 Accuracy: 0.5901\n",
      "Epoch: 087, Loss: 0.6711, Val_auc: 0.6661, Test_auc: 0.6548 Accuracy: 0.5889\n",
      "Epoch: 088, Loss: 0.6802, Val_auc: 0.6735, Test_auc: 0.6514 Accuracy: 0.6113\n",
      "Epoch: 089, Loss: 0.6702, Val_auc: 0.6769, Test_auc: 0.6537 Accuracy: 0.6054\n",
      "Epoch: 090, Loss: 0.6722, Val_auc: 0.6762, Test_auc: 0.6573 Accuracy: 0.6045\n",
      "Epoch: 091, Loss: 0.6638, Val_auc: 0.6744, Test_auc: 0.6615 Accuracy: 0.6022\n",
      "Epoch: 092, Loss: 0.6615, Val_auc: 0.6608, Test_auc: 0.6693 Accuracy: 0.6055\n",
      "Epoch: 093, Loss: 0.6647, Val_auc: 0.6596, Test_auc: 0.6714 Accuracy: 0.6154\n",
      "Epoch: 094, Loss: 0.6681, Val_auc: 0.6777, Test_auc: 0.6737 Accuracy: 0.6181\n",
      "Epoch: 095, Loss: 0.6657, Val_auc: 0.6770, Test_auc: 0.6576 Accuracy: 0.6013\n",
      "Epoch: 096, Loss: 0.6716, Val_auc: 0.6746, Test_auc: 0.6626 Accuracy: 0.5942\n",
      "Epoch: 097, Loss: 0.6641, Val_auc: 0.6746, Test_auc: 0.6784 Accuracy: 0.5943\n",
      "Epoch: 098, Loss: 0.6867, Val_auc: 0.6753, Test_auc: 0.6777 Accuracy: 0.5971\n",
      "Epoch: 099, Loss: 0.6641, Val_auc: 0.6778, Test_auc: 0.6807 Accuracy: 0.5979\n",
      "Epoch: 100, Loss: 0.6630, Val_auc: 0.6748, Test_auc: 0.6873 Accuracy: 0.6021\n",
      "Final Test_auc: 0.6873, Best Acc: 0.6021\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss, acc = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "        final_test_acc = acc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val_auc: {val_auc:.4f}, '\n",
    "          f'Test_auc: {test_auc:.4f}', f'Accuracy: {acc:.4f}')\n",
    "\n",
    "print(f'Final Test_auc: {final_test_auc:.4f}, Best Acc: {final_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test.edge_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(train_data.x, train_data.edge_index)\n",
    "final_edge_index_train = model.decode_all(z)\n",
    "predictions_df = pd.DataFrame(final_edge_index_train.t().numpy(), columns=['source', 'target'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107324391</th>\n",
       "      <td>10495</td>\n",
       "      <td>10491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107324392</th>\n",
       "      <td>10495</td>\n",
       "      <td>10492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107324393</th>\n",
       "      <td>10495</td>\n",
       "      <td>10493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107324394</th>\n",
       "      <td>10495</td>\n",
       "      <td>10494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107324395</th>\n",
       "      <td>10495</td>\n",
       "      <td>10495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107324396 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source  target\n",
       "0               0       0\n",
       "1               0       1\n",
       "2               0       2\n",
       "3               0       3\n",
       "4               0       4\n",
       "...           ...     ...\n",
       "107324391   10495   10491\n",
       "107324392   10495   10492\n",
       "107324393   10495   10493\n",
       "107324394   10495   10494\n",
       "107324395   10495   10495\n",
       "\n",
       "[107324396 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4394, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels = train_data.edge_label_index\n",
    "actual_labels.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(data_test.x, data_test.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840883</th>\n",
       "      <td>7599</td>\n",
       "      <td>7595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840884</th>\n",
       "      <td>7599</td>\n",
       "      <td>7596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840885</th>\n",
       "      <td>7599</td>\n",
       "      <td>7597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840886</th>\n",
       "      <td>7599</td>\n",
       "      <td>7598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840887</th>\n",
       "      <td>7599</td>\n",
       "      <td>7599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54840888 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  target  Predicted\n",
       "0              0       0          1\n",
       "1              0       1          1\n",
       "2              0       3          1\n",
       "3              0       4          1\n",
       "4              0       6          1\n",
       "...          ...     ...        ...\n",
       "54840883    7599    7595          1\n",
       "54840884    7599    7596          1\n",
       "54840885    7599    7597          1\n",
       "54840886    7599    7598          1\n",
       "54840887    7599    7599          1\n",
       "\n",
       "[54840888 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the predicted edge indices to a DataFrame\n",
    "predictions_df = pd.DataFrame(final_edge_index.t().numpy(), columns=['source', 'target'])\n",
    "\n",
    "# Add a 'Predicted' column with a value of 1 to indicate that these are predicted edges\n",
    "# because the model only predicts the existence of edges\n",
    "predictions_df['Predicted'] = 1\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3425</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4832</td>\n",
       "      <td>6317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4984</td>\n",
       "      <td>7298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385</td>\n",
       "      <td>5481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1548</td>\n",
       "      <td>2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>717</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>1731</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>426</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>992</td>\n",
       "      <td>1755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target\n",
       "0       3425    4524\n",
       "1       1620    2617\n",
       "2       4832    6317\n",
       "3       4984    7298\n",
       "4        385    5481\n",
       "...      ...     ...\n",
       "3493    1548    2957\n",
       "3494     717    1756\n",
       "3495    1731    3976\n",
       "3496     426    1120\n",
       "3497     992    1755\n",
       "\n",
       "[3498 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = true_test.merge(predictions_df, on=['source', 'target'], how='left')\n",
    "merged_df['Predicted'] = merged_df['Predicted'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3425</td>\n",
       "      <td>4524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620</td>\n",
       "      <td>2617</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4832</td>\n",
       "      <td>6317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4984</td>\n",
       "      <td>7298</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385</td>\n",
       "      <td>5481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1548</td>\n",
       "      <td>2957</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>717</td>\n",
       "      <td>1756</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>1731</td>\n",
       "      <td>3976</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>426</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>992</td>\n",
       "      <td>1755</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target  Predicted\n",
       "0       3425    4524        1.0\n",
       "1       1620    2617        1.0\n",
       "2       4832    6317        1.0\n",
       "3       4984    7298        1.0\n",
       "4        385    5481        1.0\n",
       "...      ...     ...        ...\n",
       "3493    1548    2957        1.0\n",
       "3494     717    1756        1.0\n",
       "3495    1731    3976        1.0\n",
       "3496     426    1120        1.0\n",
       "3497     992    1755        1.0\n",
       "\n",
       "[3498 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with index and predicted labels\n",
    "submission = pd.DataFrame({'ID': merged_df.index, 'Predicted': merged_df.Predicted})\n",
    "\n",
    "submission.to_csv('../submission/GNN/predictions_gnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

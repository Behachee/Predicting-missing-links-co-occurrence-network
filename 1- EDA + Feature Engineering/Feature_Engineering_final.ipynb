{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_columns', None)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx.algorithms.community as nx_community\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/node_information.csv\", header=None)\n",
    "test_set = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/test.txt\", sep=\" \", header=None, names=['source', 'target'])\n",
    "train_set = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/train.txt\", sep=\" \", header=None, names=['source', 'target', 'label'])\n",
    "\n",
    "# Graph creation\n",
    "G = nx.from_pandas_edgelist(train_set, 'source', 'target', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>degree_source</th>\n",
       "      <th>centrality_source</th>\n",
       "      <th>degree_target</th>\n",
       "      <th>centrality_target</th>\n",
       "      <th>community_source</th>\n",
       "      <th>community_target</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>...</th>\n",
       "      <th>923_target</th>\n",
       "      <th>924_target</th>\n",
       "      <th>925_target</th>\n",
       "      <th>926_target</th>\n",
       "      <th>927_target</th>\n",
       "      <th>928_target</th>\n",
       "      <th>929_target</th>\n",
       "      <th>930_target</th>\n",
       "      <th>931_target</th>\n",
       "      <th>932_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>939</td>\n",
       "      <td>3809</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>361</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2442</td>\n",
       "      <td>5784</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>3809</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>361</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>857</td>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>21</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1358</td>\n",
       "      <td>5722</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  label  degree_source  centrality_source  degree_target  \\\n",
       "0     939    3809      1              4           0.001112            361   \n",
       "1    2442    5784      1             11           0.003059              4   \n",
       "2     179    3809      1              8           0.002225            361   \n",
       "3     857    2280      1              9           0.002503             21   \n",
       "4    1358    5722      1              3           0.000834             17   \n",
       "\n",
       "   centrality_target  community_source  community_target   jaccard  ...  \\\n",
       "0           0.100389                 2                 0  0.000000  ...   \n",
       "1           0.001112                 3                 3  0.071429  ...   \n",
       "2           0.100389                 0                 0  0.005450  ...   \n",
       "3           0.005840                 0                 4  0.000000  ...   \n",
       "4           0.004727                 2                 2  0.000000  ...   \n",
       "\n",
       "   923_target  924_target  925_target  926_target  927_target  928_target  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   929_target  930_target  931_target  932_target  \n",
       "0         1.0         0.0         0.0         0.0  \n",
       "1         0.0         0.0         0.0         0.0  \n",
       "2         1.0         0.0         0.0         0.0  \n",
       "3         0.0         0.0         0.0         0.0  \n",
       "4         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 9342 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salton_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / ((degree_u * degree_v) ** 0.5)\n",
    "\n",
    "def sorenson_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, 2 * common_neighbors / (degree_u + degree_v)\n",
    "\n",
    "\n",
    "def hub_promoted_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / min(degree_u, degree_v)\n",
    "\n",
    "def hub_depressed_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / max(degree_u, degree_v)\n",
    "\n",
    "def adamic_adar_index(G, edges):\n",
    "    for u, v in edges:\n",
    "        score = 0\n",
    "        for w in nx.common_neighbors(G, u, v):\n",
    "            degree_w = G.degree(w)\n",
    "            if degree_w > 1:\n",
    "                score += 1 / np.log(degree_w)\n",
    "        yield u, v, score\n",
    "\n",
    "# Creer une fonction qui ajoute des features (degree, centrality, clustering) Ã  un graphes et qui merge node_info avec le graphe\n",
    "def add_node_attributes(df, node_info):\n",
    "     # CrÃ©er un graphe Ã  partir du df\n",
    "     if 'label' in df.columns:\n",
    "        G = nx.from_pandas_edgelist(df, 'source', 'target', 'label')\n",
    "     else:\n",
    "        G = nx.from_pandas_edgelist(df, 'source', 'target')\n",
    "\n",
    "     # Calculer les caractÃ©ristiques\n",
    "     df['degree_source'] = df['source'].apply(lambda x: G.degree(x))\n",
    "     df['centrality_source'] = df['source'].apply(lambda x: nx.degree_centrality(G)[x])\n",
    "     #df['clustering_source'] = df['source'].apply(lambda x: nx.clustering(G)[x])\n",
    "\n",
    "     df['degree_target'] = df['target'].apply(lambda x: G.degree(x))\n",
    "     df['centrality_target'] = df['target'].apply(lambda x: nx.degree_centrality(G)[x])\n",
    "     #df['clustering_target'] = df['target'].apply(lambda x: nx.clustering(G)[x])\n",
    "\n",
    "     # DÃ©tecter les communautÃ©s et crÃ©er une caractÃ©ristique de communautÃ©\n",
    "     communities = nx_community.greedy_modularity_communities(G)\n",
    "     community_map = {}\n",
    "     for i, community in enumerate(communities):\n",
    "          for node in community:\n",
    "               community_map[node] = i\n",
    "     df['community_source'] = df['source'].apply(lambda x: community_map[x])\n",
    "     df['community_target'] = df['target'].apply(lambda x: community_map[x])\n",
    "\n",
    "     # Calculer le coefficient de Jaccard\n",
    "     df['jaccard'] = [i[2] for i in nx.jaccard_coefficient(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de Salton\n",
    "     df['salton'] = [i[2] for i in salton_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de Sorenson\n",
    "     df['sorenson'] = [i[2] for i in sorenson_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de Hub Promoted\n",
    "     df['hub_promoted'] = [i[2] for i in hub_promoted_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de Hub Depressed\n",
    "     df['hub_depressed'] = [i[2] for i in hub_depressed_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de Leicht-Holme-Newman\n",
    "     df['leicht_holme_newman'] = [i[2] for i in nx.preferential_attachment(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de adamic_adar\n",
    "     df['adamic_adar'] = [i[2] for i in adamic_adar_index(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similaritÃ© de resource_allocation_index\n",
    "     df['resource_allocation'] = [i[2] for i in nx.resource_allocation_index(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer les common neighbors\n",
    "     df['common_neighbors'] = df.apply(lambda x: len(list(nx.common_neighbors(G, x['source'], x['target']))), axis=1)\n",
    "\n",
    "     df['resource_allocation'] = [i[2] for i in nx.resource_allocation_index(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer les common neighbors\n",
    "     df['common_neighbors'] = df.apply(lambda x: len(list(nx.common_neighbors(G, x['source'], x['target']))), axis=1)\n",
    "\n",
    "    # Calculate eigenvector centrality\n",
    "     eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "     df['eigenvector_centrality_source'] = df['source'].apply(lambda x: eigenvector_centrality.get(x, 0))\n",
    "     df['eigenvector_centrality_target'] = df['target'].apply(lambda x: eigenvector_centrality.get(x, 0))\n",
    "\n",
    "     # Fusionner node_info avec le df\n",
    "     node_info.rename(columns={0: 'node_id'}, inplace=True)\n",
    "     df = df.merge(node_info, left_on='source', right_on='node_id', how='left')\n",
    "     # rename toutes les colonnes de node_info ajouter par \"nom_col\"+\"source\"\n",
    "     df.rename(columns={col: str(col) + '_source' for col in node_info.columns[1:]}, inplace=True)\n",
    "     df.drop('node_id', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "     df = df.merge(node_info, left_on='target', right_on='node_id', how='left')\n",
    "     # rename toutes les colonnes de node_info ajouter par \"nom_col\"+\"source\"\n",
    "     df.rename(columns={col: str(col) + '_target' for col in node_info.columns[1:]}, inplace=True)\n",
    "     df.drop('node_id', axis=1, inplace=True)\n",
    "     return df\n",
    "\n",
    "# Ajouter les caractÃ©ristiques au train_set\n",
    "train_set = add_node_attributes(train_set, node_info)\n",
    "test_set = add_node_attributes(test_set, node_info)\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../data/train_set_final.csv', index=False)\n",
    "test_set.to_csv('../data/test_set_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_columns', None)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx.algorithms.community as nx_community\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/node_information.csv\", header=None)\n",
    "test_set = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/test.txt\", sep=\" \", header=None, names=['source', 'target'])\n",
    "train_set = pd.read_csv(\"/Users/jojolapatate/Documents/GitHub/Predicting-missing-links-co-occurrence-network/data/train.txt\", sep=\" \", header=None, names=['source', 'target', 'label'])\n",
    "\n",
    "# Graph creation\n",
    "G = nx.from_pandas_edgelist(train_set, 'source', 'target', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>degree_source</th>\n",
       "      <th>centrality_source</th>\n",
       "      <th>degree_target</th>\n",
       "      <th>centrality_target</th>\n",
       "      <th>community_source</th>\n",
       "      <th>community_target</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>...</th>\n",
       "      <th>923_target</th>\n",
       "      <th>924_target</th>\n",
       "      <th>925_target</th>\n",
       "      <th>926_target</th>\n",
       "      <th>927_target</th>\n",
       "      <th>928_target</th>\n",
       "      <th>929_target</th>\n",
       "      <th>930_target</th>\n",
       "      <th>931_target</th>\n",
       "      <th>932_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>939</td>\n",
       "      <td>3809</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>361</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2442</td>\n",
       "      <td>5784</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>3809</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>361</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>857</td>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>21</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1358</td>\n",
       "      <td>5722</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target  label  degree_source  centrality_source  degree_target  \\\n",
       "0     939    3809      1              4           0.001112            361   \n",
       "1    2442    5784      1             11           0.003059              4   \n",
       "2     179    3809      1              8           0.002225            361   \n",
       "3     857    2280      1              9           0.002503             21   \n",
       "4    1358    5722      1              3           0.000834             17   \n",
       "\n",
       "   centrality_target  community_source  community_target   jaccard  ...  \\\n",
       "0           0.100389                 2                 0  0.000000  ...   \n",
       "1           0.001112                 3                 3  0.071429  ...   \n",
       "2           0.100389                 0                 0  0.005450  ...   \n",
       "3           0.005840                 0                 4  0.000000  ...   \n",
       "4           0.004727                 2                 2  0.000000  ...   \n",
       "\n",
       "   923_target  924_target  925_target  926_target  927_target  928_target  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   929_target  930_target  931_target  932_target  \n",
       "0         1.0         0.0         0.0         0.0  \n",
       "1         0.0         0.0         0.0         0.0  \n",
       "2         1.0         0.0         0.0         0.0  \n",
       "3         0.0         0.0         0.0         0.0  \n",
       "4         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 9342 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salton_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / ((degree_u * degree_v) ** 0.5)\n",
    "\n",
    "def sorenson_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, 2 * common_neighbors / (degree_u + degree_v)\n",
    "\n",
    "\n",
    "def hub_promoted_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / min(degree_u, degree_v)\n",
    "\n",
    "def hub_depressed_similarity(G, edges):\n",
    "    for u, v in edges:\n",
    "        common_neighbors = len(list(nx.common_neighbors(G, u, v)))\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        yield u, v, common_neighbors / max(degree_u, degree_v)\n",
    "\n",
    "def adamic_adar_index(G, edges):\n",
    "    for u, v in edges:\n",
    "        score = 0\n",
    "        for w in nx.common_neighbors(G, u, v):\n",
    "            degree_w = G.degree(w)\n",
    "            if degree_w > 1:\n",
    "                score += 1 / np.log(degree_w)\n",
    "        yield u, v, score\n",
    "\n",
    "# Creer une fonction qui ajoute des features (degree, centrality, clustering) à un graphes et qui merge node_info avec le graphe\n",
    "def add_node_attributes(df, node_info):\n",
    "     # Créer un graphe à partir du df\n",
    "     if 'label' in df.columns:\n",
    "        G = nx.from_pandas_edgelist(df, 'source', 'target', 'label')\n",
    "     else:\n",
    "        G = nx.from_pandas_edgelist(df, 'source', 'target')\n",
    "\n",
    "     # Calculer les caractéristiques\n",
    "     df['degree_source'] = df['source'].apply(lambda x: G.degree(x))\n",
    "     df['centrality_source'] = df['source'].apply(lambda x: nx.degree_centrality(G)[x])\n",
    "     #df['clustering_source'] = df['source'].apply(lambda x: nx.clustering(G)[x])\n",
    "\n",
    "     df['degree_target'] = df['target'].apply(lambda x: G.degree(x))\n",
    "     df['centrality_target'] = df['target'].apply(lambda x: nx.degree_centrality(G)[x])\n",
    "     #df['clustering_target'] = df['target'].apply(lambda x: nx.clustering(G)[x])\n",
    "\n",
    "     # Détecter les communautés et créer une caractéristique de communauté\n",
    "     communities = nx_community.greedy_modularity_communities(G)\n",
    "     community_map = {}\n",
    "     for i, community in enumerate(communities):\n",
    "          for node in community:\n",
    "               community_map[node] = i\n",
    "     df['community_source'] = df['source'].apply(lambda x: community_map[x])\n",
    "     df['community_target'] = df['target'].apply(lambda x: community_map[x])\n",
    "\n",
    "     # Calculer le coefficient de Jaccard\n",
    "     df['jaccard'] = [i[2] for i in nx.jaccard_coefficient(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer le coefficient de similarité de Salton\n",
    "     df['salton'] = [i[2] for i in salton_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similarité de Sorenson\n",
    "     df['sorenson'] = [i[2] for i in sorenson_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similarité de Hub Promoted\n",
    "     df['hub_promoted'] = [i[2] for i in hub_promoted_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similarité de Hub Depressed\n",
    "     df['hub_depressed'] = [i[2] for i in hub_depressed_similarity(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similarité de Leicht-Holme-Newman\n",
    "     df['leicht_holme_newman'] = [i[2] for i in nx.preferential_attachment(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer le coefficient de similarité de adamic_adar\n",
    "     df['adamic_adar'] = [i[2] for i in adamic_adar_index(G, df[['source', 'target']].values.tolist())]\n",
    "\n",
    "     # Calculer le coefficient de similarité de resource_allocation_index\n",
    "     df['resource_allocation'] = [i[2] for i in nx.resource_allocation_index(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer les common neighbors\n",
    "     df['common_neighbors'] = df.apply(lambda x: len(list(nx.common_neighbors(G, x['source'], x['target']))), axis=1)\n",
    "\n",
    "     df['resource_allocation'] = [i[2] for i in nx.resource_allocation_index(G, df[['source', 'target']].values)]\n",
    "\n",
    "     # Calculer les common neighbors\n",
    "     df['common_neighbors'] = df.apply(lambda x: len(list(nx.common_neighbors(G, x['source'], x['target']))), axis=1)\n",
    "\n",
    "    # Calculate eigenvector centrality\n",
    "     eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "     df['eigenvector_centrality_source'] = df['source'].apply(lambda x: eigenvector_centrality.get(x, 0))\n",
    "     df['eigenvector_centrality_target'] = df['target'].apply(lambda x: eigenvector_centrality.get(x, 0))\n",
    "\n",
    "     # Fusionner node_info avec le df\n",
    "     node_info.rename(columns={0: 'node_id'}, inplace=True)\n",
    "     df = df.merge(node_info, left_on='source', right_on='node_id', how='left')\n",
    "     # rename toutes les colonnes de node_info ajouter par \"nom_col\"+\"source\"\n",
    "     df.rename(columns={col: str(col) + '_source' for col in node_info.columns[1:]}, inplace=True)\n",
    "     df.drop('node_id', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "     df = df.merge(node_info, left_on='target', right_on='node_id', how='left')\n",
    "     # rename toutes les colonnes de node_info ajouter par \"nom_col\"+\"source\"\n",
    "     df.rename(columns={col: str(col) + '_target' for col in node_info.columns[1:]}, inplace=True)\n",
    "     df.drop('node_id', axis=1, inplace=True)\n",
    "     return df\n",
    "\n",
    "# Ajouter les caractéristiques au train_set\n",
    "train_set = add_node_attributes(train_set, node_info)\n",
    "test_set = add_node_attributes(test_set, node_info)\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../data/train_set_final.csv', index=False)\n",
    "test_set.to_csv('../data/test_set_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
